[TOC]

## 1.Bi-DAF简介
本周着重学习了机器阅读理解模型中的Bi-DAF模型，BiDAF采用双向的attention流机制，得到qurery-to-context, context-to-query两个方向的注意力信息，从而获得相关问句和原文之间的关联程度的表征信息。

## 2.模型
[model](note/model.png)

### 2.1 Embedding层
Bi-DAF模型对句中的单词会按两种方式分别做嵌入处理。
(1) word embedding，通过Glove生成词向量
(2) char embedding，对字符进行嵌入，并对生成的字符向量做卷积与池化，使得新生的向量与word embedding方式在seq_len的维度上相等
(3) 拼接，讲字符词向量与单词词向量拼接

### 2.2 Highway Network
部分输入会经过FNN进行非线性映射变换，而另一部分输入可直接进入下一模块中。
这么做的好处是可保留更多的原始信息，同时，在反向传播的时候，可以让更多的梯度信息回流到输入，而不会经过非线性转化。

### 2.3 上下文嵌入
这一模块采用两层双向LSTM，对单词之间交互特征进行建模。

## 下周学习计划
+ 该模型的注意力模块仍有些不清楚的地方，待下周继续研究后，补齐模型剩下部分
+ 完成代码剩余部分，训练模型，并验证模型的效果